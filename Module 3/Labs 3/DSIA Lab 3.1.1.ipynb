{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PopLE1ywNQsa"
   },
   "source": [
    "![alt text](https://i.imgur.com/1WaY7aA.png)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e45O_NedNQsd"
   },
   "source": [
    "# Lab 3.1.1 \n",
    "# *Data Wrangling and Munging with Pandas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qr08YR1PNQsf"
   },
   "source": [
    "## Part 1: Wrangling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RH9yA6LINQsh"
   },
   "source": [
    "The term \"data wrangling\" is analogous to capturing wild horses and getting them into a fenced area; the horses are data and the fencing is your computer. The more common data wrangling tasks include:\n",
    "\n",
    "- reading flat files\n",
    "- reading Excel files\n",
    "- downloading from web pages\n",
    "  - csv\n",
    "  - html\n",
    "  - json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Znip5IF3NQsk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8G9iecYNQsr"
   },
   "source": [
    "*It is good practice to display the library version numbers for future reference:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GuNeJ6hlNQst"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy:  1.16.2\n",
      "Pandas:  0.24.2\n"
     ]
    }
   ],
   "source": [
    "print('Numpy: ', np.__version__)\n",
    "print('Pandas: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzTKAG1LNQsx"
   },
   "source": [
    "### CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE2wYKPNNQsy"
   },
   "source": [
    "Below are three attempts to load the file \"bikeshare.csv\" into a DataFrame named `bikes`. Why are they wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\praty\\\\Documents\\\\DSIA\\\\DSIA-SYD-FT-Projects-201907\\\\Sarita\\\\Labs\\\\Lab3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZV2HMWarNQsz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant     dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  1/01/2011       1   0     1   0        0        6           0   \n",
      "1        2  1/01/2011       1   0     1   1        0        6           0   \n",
      "2        3  1/01/2011       1   0     1   2        0        6           0   \n",
      "3        4  1/01/2011       1   0     1   3        0        6           0   \n",
      "4        5  1/01/2011       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praty\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# wrong:\n",
    "bikes = pd.read_table('../data3/bikeshare.csv', delimiter=',')\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('../data3/bikeshare.csv', header = 1, delimiter=',')\n",
    "print(bikes.head())\n",
    "print()\n",
    "\"\"\"\n",
    "# wrong:\n",
    "bikes = pd.read_table('../data3/bikeshare.csv', delimiter=',')\n",
    "print(bikes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant     dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  1/01/2011       1   0     1   0        0        6           0   \n",
      "1        2  1/01/2011       1   0     1   1        0        6           0   \n",
      "2        3  1/01/2011       1   0     1   2        0        6           0   \n",
      "3        4  1/01/2011       1   0     1   3        0        6           0   \n",
      "4        5  1/01/2011       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    }
   ],
   "source": [
    "bikes = pd.read_csv('../data3/bikeshare.csv')\n",
    "print(bikes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSiMJN9NNQs4"
   },
   "source": [
    "?:\n",
    "ANSWER: Case 1 treats headings as just another data row. Case 2 treats the 1st data row as the column header. Case 3 gets the header right (row 0), but reads each row as a single column (Nb. the other two make that same mistake). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDFYVoPINQs6"
   },
   "source": [
    "Load the file \"bikeshare.csv\" into a DataFrame named `bikes`, and confirm that it was loaded properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wH2wuPznNQs8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    }
   ],
   "source": [
    "#ANSWER: pd is a read.csv,data frame\n",
    "bikes = pd.read_csv('../data3/bikeshare.csv')\n",
    "print(bikes.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEwczD29NQtA"
   },
   "source": [
    "Note that we could have used `read.csv()` above. When is `read_table()` necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OsmNWLXNQtB"
   },
   "source": [
    "?:\n",
    "ANSWER: When `sep` is not the comma character, or we need fine control that `read.csv()` does not provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pPEoeHGGNQtC"
   },
   "source": [
    "Flat files can be full of surprises. Here are some issues to watch out for:\n",
    "\n",
    "- separator character is something other than the comma\n",
    "  - \";\", \"|\", and tab are popular\n",
    "- newline character is something other than what the O/S expects \n",
    "  - Tip: Don't hard-code the character codes for carriage returns, linefeeds, etc. Use Python's built-in representation instead (e.g. Python translates \"\\n\" to the newline character and \"\\t\" to the tab character on any O/S).\n",
    "- truncated lines\n",
    "  - if there are empty fields at the end of a line it is possible that their separators will be missing, resulting in a \"jagged\" file\n",
    "- embedded commas or quotes\n",
    "  - a free-text field containing embedded commas may split into separate fields on input\n",
    "  - a free-text field containing embedded quotes may not parse correctly\n",
    "- unescaped characters\n",
    "  - the \"\\\" character indicates a control code to Python, which will break the I/O\n",
    "    - e.g. the substring \"\\u0123\" will be interpreted as Unicode(0123) -- which may not be what the file creator intended\n",
    "  - these may need to be fixed by loading whole strings and then parsing into a new data frame\n",
    "  \n",
    "Tip: Most issues can be delth with by correctly specifying the parameters of the function you use to load the file. Read the doco before reading the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0G5PtA2NQtC"
   },
   "source": [
    "### Reading Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYELgCw6NQtD"
   },
   "outputs": [],
   "source": [
    "from pandas import ExcelFile  # Nb. Need to install xlrd from conda (it does not automatically install with pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDjzKP6nNQtF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species_No</th>\n",
       "      <th>Petal_width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Sepal_length</th>\n",
       "      <th>Species_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Species_No  Petal_width  Petal_length  Sepal_width  Sepal_length  \\\n",
       "0             1          0.2           1.4          3.5           5.1   \n",
       "1             1          0.2           1.4          3.0           4.9   \n",
       "2             1          0.2           1.3          3.2           4.7   \n",
       "3             1          0.2           1.5          3.1           4.6   \n",
       "4             1          0.2           1.4          3.6           5.0   \n",
       "5             1          0.4           1.7          3.9           5.4   \n",
       "6             1          0.3           1.4          3.4           4.6   \n",
       "7             1          0.2           1.5          3.4           5.0   \n",
       "8             1          0.2           1.4          2.9           4.4   \n",
       "9             1          0.1           1.5          3.1           4.9   \n",
       "10            1          0.2           1.5          3.7           5.4   \n",
       "11            1          0.2           1.6          3.4           4.8   \n",
       "12            1          0.1           1.4          3.0           4.8   \n",
       "13            1          0.1           1.1          3.0           4.3   \n",
       "14            1          0.2           1.2          4.0           5.8   \n",
       "15            1          0.4           1.5          4.4           5.7   \n",
       "16            1          0.4           1.3          3.9           5.4   \n",
       "17            1          0.3           1.4          3.5           5.1   \n",
       "18            1          0.3           1.7          3.8           5.7   \n",
       "19            1          0.3           1.5          3.8           5.1   \n",
       "20            1          0.2           1.7          3.4           5.4   \n",
       "21            1          0.4           1.5          3.7           5.1   \n",
       "22            1          0.2           1.0          3.6           4.6   \n",
       "23            1          0.5           1.7          3.3           5.1   \n",
       "24            1          0.2           1.9          3.4           4.8   \n",
       "25            1          0.2           1.6          3.0           5.0   \n",
       "26            1          0.4           1.6          3.4           5.0   \n",
       "27            1          0.2           1.5          3.5           5.2   \n",
       "28            1          0.2           1.4          3.4           5.2   \n",
       "29            1          0.2           1.6          3.2           4.7   \n",
       "..          ...          ...           ...          ...           ...   \n",
       "120           3          2.3           5.7          3.2           6.9   \n",
       "121           3          2.0           4.9          2.8           5.6   \n",
       "122           3          2.0           6.7          2.8           7.7   \n",
       "123           3          1.8           4.9          2.7           6.3   \n",
       "124           3          2.1           5.7          3.3           6.7   \n",
       "125           3          1.8           6.0          3.2           7.2   \n",
       "126           3          1.8           4.8          2.8           6.2   \n",
       "127           3          1.8           4.9          3.0           6.1   \n",
       "128           3          2.1           5.6          2.8           6.4   \n",
       "129           3          1.6           5.8          3.0           7.2   \n",
       "130           3          1.9           6.1          2.8           7.4   \n",
       "131           3          2.0           6.4          3.8           7.9   \n",
       "132           3          2.2           5.6          2.8           6.4   \n",
       "133           3          1.5           5.1          2.8           6.3   \n",
       "134           3          1.4           5.6          2.6           6.1   \n",
       "135           3          2.3           6.1          3.0           7.7   \n",
       "136           3          2.4           5.6          3.4           6.3   \n",
       "137           3          1.8           5.5          3.1           6.4   \n",
       "138           3          1.8           4.8          3.0           6.0   \n",
       "139           3          2.1           5.4          3.1           6.9   \n",
       "140           3          2.4           5.6          3.1           6.7   \n",
       "141           3          2.3           5.1          3.1           6.9   \n",
       "142           3          1.9           5.1          2.7           5.8   \n",
       "143           3          2.3           5.9          3.2           6.8   \n",
       "144           3          2.5           5.7          3.3           6.7   \n",
       "145           3          2.3           5.2          3.0           6.7   \n",
       "146           3          1.9           5.0          2.5           6.3   \n",
       "147           3          2.0           5.2          3.0           6.5   \n",
       "148           3          2.3           5.4          3.4           6.2   \n",
       "149           3          1.8           5.1          3.0           5.9   \n",
       "\n",
       "    Species_name  \n",
       "0         Setosa  \n",
       "1         Setosa  \n",
       "2         Setosa  \n",
       "3         Setosa  \n",
       "4         Setosa  \n",
       "5         Setosa  \n",
       "6         Setosa  \n",
       "7         Setosa  \n",
       "8         Setosa  \n",
       "9         Setosa  \n",
       "10        Setosa  \n",
       "11        Setosa  \n",
       "12        Setosa  \n",
       "13        Setosa  \n",
       "14        Setosa  \n",
       "15        Setosa  \n",
       "16        Setosa  \n",
       "17        Setosa  \n",
       "18        Setosa  \n",
       "19        Setosa  \n",
       "20        Setosa  \n",
       "21        Setosa  \n",
       "22        Setosa  \n",
       "23        Setosa  \n",
       "24        Setosa  \n",
       "25        Setosa  \n",
       "26        Setosa  \n",
       "27        Setosa  \n",
       "28        Setosa  \n",
       "29        Setosa  \n",
       "..           ...  \n",
       "120    Verginica  \n",
       "121    Verginica  \n",
       "122    Verginica  \n",
       "123    Verginica  \n",
       "124    Verginica  \n",
       "125    Verginica  \n",
       "126    Verginica  \n",
       "127    Verginica  \n",
       "128    Verginica  \n",
       "129    Verginica  \n",
       "130    Verginica  \n",
       "131    Verginica  \n",
       "132    Verginica  \n",
       "133    Verginica  \n",
       "134    Verginica  \n",
       "135    Verginica  \n",
       "136    Verginica  \n",
       "137    Verginica  \n",
       "138    Verginica  \n",
       "139    Verginica  \n",
       "140    Verginica  \n",
       "141    Verginica  \n",
       "142    Verginica  \n",
       "143    Verginica  \n",
       "144    Verginica  \n",
       "145    Verginica  \n",
       "146    Verginica  \n",
       "147    Verginica  \n",
       "148    Verginica  \n",
       "149    Verginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data3/Iris.xls', sheet_name = 'Data')\n",
    "df                                                           # changed the sheet name as it was wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x0a2XhAZNQtH"
   },
   "source": [
    "So, this file appears to have an embedded table of aggregates on the same sheet as the raw data (a naughty but common practice amongst analysts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjWx-Xo0NQtH"
   },
   "source": [
    "It is usually better to load data correctly than to meddle with the source file or load it 'warts and all' and then try to parse it in code. The Pandas functions for reading files have parameters that provide the control we need. For ecxample, we could make multiple calls to `read_excel()`, using combinations of the `header`, `usecols`, `skiprows`, `nrows`, and `skipfooter` parameters to load one table at a time from a spreadsheet with multiple tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tC5kzTsMNQtI"
   },
   "source": [
    "Load the above file without the unwanted columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-P70uSXsNQtI"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTkOz1KsNQtK"
   },
   "source": [
    "### Importing Data Directly from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFHi_S4fNQtK"
   },
   "source": [
    "We usually want to store a local copy of a data file that we download from the Web, but when data retention is not a priority it is convenient to download the data directly into our running Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jS7P3oXQNQtL"
   },
   "source": [
    "#### Importing Text Files from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-hzkxRRNQtL"
   },
   "source": [
    "The web is the 'wild west' of data formats. However, we can usually expect good behaviour from files that are automatically generated by a service, such as the earthquake report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFuaZ82hNQtM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-15T06:21:18.973Z</td>\n",
       "      <td>61.149</td>\n",
       "      <td>-150.4553</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.7</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-07-15T06:25:31.964Z</td>\n",
       "      <td>30km WSW of Anchorage, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automatic</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-15T05:59:39.107Z</td>\n",
       "      <td>-10.012</td>\n",
       "      <td>118.7928</td>\n",
       "      <td>38.72</td>\n",
       "      <td>4.9</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3.664</td>\n",
       "      <td>1.22</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-07-15T06:25:43.040Z</td>\n",
       "      <td>47km SW of Panenggoede, Indonesia</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>5.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.074</td>\n",
       "      <td>57.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  latitude  longitude  depth  mag magType  nst  \\\n",
       "0  2019-07-15T06:21:18.973Z    61.149  -150.4553   0.40  2.7      ml  NaN   \n",
       "1  2019-07-15T05:59:39.107Z   -10.012   118.7928  38.72  4.9      mb  NaN   \n",
       "\n",
       "    gap   dmin   rms  ...                   updated  \\\n",
       "0   NaN    NaN  0.78  ...  2019-07-15T06:25:31.964Z   \n",
       "1  85.0  3.664  1.22  ...  2019-07-15T06:25:43.040Z   \n",
       "\n",
       "                               place        type horizontalError depthError  \\\n",
       "0      30km WSW of Anchorage, Alaska  earthquake             NaN        0.2   \n",
       "1  47km SW of Panenggoede, Indonesia  earthquake             5.3        7.2   \n",
       "\n",
       "   magError  magNst     status  locationSource magSource  \n",
       "0       NaN     NaN  automatic              ak        ak  \n",
       "1     0.074    57.0   reviewed              us        us  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_hour.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGgcXCzyNQtN"
   },
   "source": [
    "#### Importing HTML Files from the Web\n",
    "\n",
    "Working with unstructured HTML files relies heavily on library functions. This one, however, is well-structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4oVabZ6NQtO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                             Bank Name                City  \\\n",
       " 0                                 The Enloe State Bank              Cooper   \n",
       " 1                  Washington Federal Bank for Savings             Chicago   \n",
       " 2      The Farmers and Merchants State Bank of Argonia             Argonia   \n",
       " 3                                  Fayette County Bank          Saint Elmo   \n",
       " 4    Guaranty Bank, (d/b/a BestBank in Georgia & Mi...           Milwaukee   \n",
       " 5                                       First NBC Bank         New Orleans   \n",
       " 6                                        Proficio Bank  Cottonwood Heights   \n",
       " 7                        Seaway Bank and Trust Company             Chicago   \n",
       " 8                               Harvest Community Bank          Pennsville   \n",
       " 9                                          Allied Bank            Mulberry   \n",
       " 10                        The Woodbury Banking Company            Woodbury   \n",
       " 11                              First CornerStone Bank     King of Prussia   \n",
       " 12                                  Trust Company Bank             Memphis   \n",
       " 13                          North Milwaukee State Bank           Milwaukee   \n",
       " 14                              Hometown National Bank            Longview   \n",
       " 15                                 The Bank of Georgia      Peachtree City   \n",
       " 16                                        Premier Bank              Denver   \n",
       " 17                                      Edgebrook Bank             Chicago   \n",
       " 18                              Doral Bank  En Español            San Juan   \n",
       " 19                   Capitol City Bank & Trust Company             Atlanta   \n",
       " 20                             Highland Community Bank             Chicago   \n",
       " 21                    First National Bank of Crestview           Crestview   \n",
       " 22                                  Northern Star Bank             Mankato   \n",
       " 23              Frontier Bank, FSB D/B/A El Paseo Bank         Palm Desert   \n",
       " 24               The National Republic Bank of Chicago             Chicago   \n",
       " 25                                      NBRS Financial          Rising Sun   \n",
       " 26                               GreenChoice Bank, fsb             Chicago   \n",
       " 27                            Eastside Commercial Bank             Conyers   \n",
       " 28                              The Freedom State Bank             Freedom   \n",
       " 29                                         Valley Bank     Fort Lauderdale   \n",
       " ..                                                 ...                 ...   \n",
       " 526                                  ANB Financial, NA         Bentonville   \n",
       " 527                                          Hume Bank                Hume   \n",
       " 528                             Douglass National Bank         Kansas City   \n",
       " 529                                  Miami Valley Bank            Lakeview   \n",
       " 530                                            NetBank          Alpharetta   \n",
       " 531                          Metropolitan Savings Bank          Pittsburgh   \n",
       " 532                                    Bank of Ephraim             Ephraim   \n",
       " 533                                      Reliance Bank        White Plains   \n",
       " 534              Guaranty National Bank of Tallahassee         Tallahassee   \n",
       " 535                                Dollar Savings Bank              Newark   \n",
       " 536                               Pulaski Savings Bank        Philadelphia   \n",
       " 537              First National Bank of Blanchardville      Blanchardville   \n",
       " 538                              Southern Pacific Bank            Torrance   \n",
       " 539                        Farmers Bank of Cheneyville         Cheneyville   \n",
       " 540                                      Bank of Alamo               Alamo   \n",
       " 541             AmTrade International Bank  En Español             Atlanta   \n",
       " 542                     Universal Federal Savings Bank             Chicago   \n",
       " 543                       Connecticut Bank of Commerce            Stamford   \n",
       " 544                                   New Century Bank     Shelby Township   \n",
       " 545                              Net 1st National Bank          Boca Raton   \n",
       " 546                                       NextBank, NA             Phoenix   \n",
       " 547                           Oakwood Deposit Bank Co.             Oakwood   \n",
       " 548                              Bank of Sierra Blanca       Sierra Blanca   \n",
       " 549                      Hamilton Bank, NA  En Español               Miami   \n",
       " 550                             Sinclair National Bank            Gravette   \n",
       " 551                                 Superior Bank, FSB            Hinsdale   \n",
       " 552                                Malta National Bank               Malta   \n",
       " 553                    First Alliance Bank & Trust Co.          Manchester   \n",
       " 554                  National State Bank of Metropolis          Metropolis   \n",
       " 555                                   Bank of Honolulu            Honolulu   \n",
       " \n",
       "      ST   CERT                Acquiring Institution        Closing Date  \\\n",
       " 0    TX  10716                   Legend Bank, N. A.        May 31, 2019   \n",
       " 1    IL  30570                   Royal Savings Bank   December 15, 2017   \n",
       " 2    KS  17719                          Conway Bank    October 13, 2017   \n",
       " 3    IL   1802            United Fidelity Bank, fsb        May 26, 2017   \n",
       " 4    WI  30003  First-Citizens Bank & Trust Company         May 5, 2017   \n",
       " 5    LA  58302                         Whitney Bank      April 28, 2017   \n",
       " 6    UT  35495                    Cache Valley Bank       March 3, 2017   \n",
       " 7    IL  19328                  State Bank of Texas    January 27, 2017   \n",
       " 8    NJ  34951  First-Citizens Bank & Trust Company    January 13, 2017   \n",
       " 9    AR     91                         Today's Bank  September 23, 2016   \n",
       " 10   GA  11297                          United Bank     August 19, 2016   \n",
       " 11   PA  35312  First-Citizens Bank & Trust Company         May 6, 2016   \n",
       " 12   TN   9956           The Bank of Fayette County      April 29, 2016   \n",
       " 13   WI  20364  First-Citizens Bank & Trust Company      March 11, 2016   \n",
       " 14   WA  35156                       Twin City Bank     October 2, 2015   \n",
       " 15   GA  35259                        Fidelity Bank     October 2, 2015   \n",
       " 16   CO  34112            United Fidelity Bank, fsb       July 10, 2015   \n",
       " 17   IL  57772             Republic Bank of Chicago         May 8, 2015   \n",
       " 18   PR  32102         Banco Popular de Puerto Rico   February 27, 2015   \n",
       " 19   GA  33938  First-Citizens Bank & Trust Company   February 13, 2015   \n",
       " 20   IL  20290            United Fidelity Bank, fsb    January 23, 2015   \n",
       " 21   FL  17557                       First NBC Bank    January 16, 2015   \n",
       " 22   MN  34983                            BankVista   December 19, 2014   \n",
       " 23   CA  34738    Bank of Southern California, N.A.    November 7, 2014   \n",
       " 24   IL    916                  State Bank of Texas    October 24, 2014   \n",
       " 25   MD   4862                          Howard Bank    October 17, 2014   \n",
       " 26   IL  28462                 Providence Bank, LLC       July 25, 2014   \n",
       " 27   GA  58125            Community & Southern Bank       July 18, 2014   \n",
       " 28   OK  12483      Alva State Bank & Trust Company       June 27, 2014   \n",
       " 29   FL  21793  Landmark Bank, National Association       June 20, 2014   \n",
       " ..   ..    ...                                  ...                 ...   \n",
       " 526  AR  33901       Pulaski Bank and Trust Company         May 9, 2008   \n",
       " 527  MO   1971                        Security Bank       March 7, 2008   \n",
       " 528  MO  24660       Liberty Bank and Trust Company    January 25, 2008   \n",
       " 529  OH  16848         The Citizens Banking Company     October 4, 2007   \n",
       " 530  GA  32575                           ING DIRECT  September 28, 2007   \n",
       " 531  PA  35353  Allegheny Valley Bank of Pittsburgh    February 2, 2007   \n",
       " 532  UT   1249                        Far West Bank       June 25, 2004   \n",
       " 533  NY  26778                     Union State Bank      March 19, 2004   \n",
       " 534  FL  26838              Hancock Bank of Florida      March 12, 2004   \n",
       " 535  NJ  31330                          No Acquirer   February 14, 2004   \n",
       " 536  PA  27203                       Earthstar Bank   November 14, 2003   \n",
       " 537  WI  11639                        The Park Bank         May 9, 2003   \n",
       " 538  CA  27094                            Beal Bank    February 7, 2003   \n",
       " 539  LA  16445            Sabine State Bank & Trust   December 17, 2002   \n",
       " 540  TN   9961                          No Acquirer    November 8, 2002   \n",
       " 541  GA  33784                          No Acquirer  September 30, 2002   \n",
       " 542  IL  29355               Chicago Community Bank       June 27, 2002   \n",
       " 543  CT  19183                   Hudson United Bank       June 26, 2002   \n",
       " 544  MI  34979                          No Acquirer      March 28, 2002   \n",
       " 545  FL  26652                       Bank Leumi USA       March 1, 2002   \n",
       " 546  AZ  22314                          No Acquirer    February 7, 2002   \n",
       " 547  OH   8966       The State Bank & Trust Company    February 1, 2002   \n",
       " 548  TX  22002     The Security State Bank of Pecos    January 18, 2002   \n",
       " 549  FL  24382     Israel Discount Bank of New York    January 11, 2002   \n",
       " 550  AR  34248                   Delta Trust & Bank   September 7, 2001   \n",
       " 551  IL  32646                Superior Federal, FSB       July 27, 2001   \n",
       " 552  OH   6629                    North Valley Bank         May 3, 2001   \n",
       " 553  NH  34264  Southern New Hampshire Bank & Trust    February 2, 2001   \n",
       " 554  IL   3815              Banterra Bank of Marion   December 14, 2000   \n",
       " 555  HI  21029                   Bank of the Orient    October 13, 2000   \n",
       " \n",
       "            Updated Date  \n",
       " 0         June 18, 2019  \n",
       " 1      February 1, 2019  \n",
       " 2     February 21, 2018  \n",
       " 3      January 29, 2019  \n",
       " 4        March 22, 2018  \n",
       " 5      January 29, 2019  \n",
       " 6      January 29, 2019  \n",
       " 7      January 29, 2019  \n",
       " 8          May 18, 2017  \n",
       " 9          May 13, 2019  \n",
       " 10    December 13, 2018  \n",
       " 11    November 13, 2018  \n",
       " 12   September 14, 2018  \n",
       " 13     January 29, 2019  \n",
       " 14    February 19, 2018  \n",
       " 15         July 9, 2018  \n",
       " 16    February 20, 2018  \n",
       " 17     January 29, 2019  \n",
       " 18     January 29, 2019  \n",
       " 19     January 29, 2019  \n",
       " 20    November 15, 2017  \n",
       " 21    November 15, 2017  \n",
       " 22      January 3, 2018  \n",
       " 23    November 10, 2016  \n",
       " 24      January 6, 2016  \n",
       " 25     January 29, 2019  \n",
       " 26    December 12, 2016  \n",
       " 27      October 6, 2017  \n",
       " 28    February 21, 2018  \n",
       " 29     January 29, 2019  \n",
       " ..                  ...  \n",
       " 526    February 1, 2019  \n",
       " 527    January 31, 2019  \n",
       " 528    October 26, 2012  \n",
       " 529  September 12, 2016  \n",
       " 530    January 31, 2019  \n",
       " 531    October 27, 2010  \n",
       " 532       April 9, 2008  \n",
       " 533       April 9, 2008  \n",
       " 534      April 17, 2018  \n",
       " 535       April 9, 2008  \n",
       " 536     October 6, 2017  \n",
       " 537        June 5, 2012  \n",
       " 538    October 20, 2008  \n",
       " 539    October 20, 2004  \n",
       " 540      March 18, 2005  \n",
       " 541  September 11, 2006  \n",
       " 542     October 6, 2017  \n",
       " 543   February 14, 2012  \n",
       " 544      March 18, 2005  \n",
       " 545       April 9, 2008  \n",
       " 546    February 5, 2015  \n",
       " 547    October 25, 2012  \n",
       " 548    November 6, 2003  \n",
       " 549  September 21, 2015  \n",
       " 550     October 6, 2017  \n",
       " 551     August 19, 2014  \n",
       " 552   November 18, 2002  \n",
       " 553   February 18, 2003  \n",
       " 554      March 17, 2005  \n",
       " 555      March 17, 2005  \n",
       " \n",
       " [556 rows x 7 columns]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.fdic.gov/bank/individual/failed/banklist.html'\n",
    "df = pd.read_html(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CaWhHAk9NQtQ"
   },
   "source": [
    "#### Importing XML Files from the Web\n",
    "\n",
    "XML files are semi-structured, but you're at the mercy of the file creator. If every record has the same format it will be much easier, but practical applications often require a lot of custom code. Here is an example that includes a nice parser class: http://www.austintaylor.io/lxml/python/pandas/xml/dataframe/2016/07/08/convert-xml-to-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ppLnAmKVNQtQ"
   },
   "source": [
    "#### Importing JSON Files from the Web\n",
    "\n",
    "Like XML, JSON files are semi-structured and may require work to capture the schema into a dataframe. Here is a simple example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VB9EoRrNQtS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>integer</th>\n",
       "      <th>datetime</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>2015-01-01 00:00:12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    integer            datetime  category\n",
       "0         5 2015-01-01 00:00:00         0\n",
       "1         5 2015-01-01 00:00:01         0\n",
       "10        5 2015-01-01 00:00:10         0\n",
       "11        5 2015-01-01 00:00:11         0\n",
       "12        8 2015-01-01 00:00:12         0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/data.json'\n",
    "\n",
    "# Load the first sheet of the JSON file into a data frame\n",
    "df = pd.read_json(url, orient = 'columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIArBrFFNQtV"
   },
   "source": [
    "## Part 2: Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aFUJrhENQtW"
   },
   "source": [
    "Data munging is manipulating data to get it into a form that we can start running analyses on (which usually means getting the data into a DataFrame). Before we get to this stage, we may need to remove headers or footers, transpose columns to rows, split wide data tables into long ones, and so on. (Nb. Excel files can be particularly troublesome, because users can format their data in mixed, complex shapes.) Essentially, we need to follow Hadley Wickham's guidelines for tidy datasets (http://vita.had.co.nz/papers/tidy-data.html):\n",
    "\n",
    "The end goal of the cleaning data process:\n",
    "\n",
    "- each variable should be in one column\n",
    "- each observation should comprise one row\n",
    "- each type of observational unit should form one table\n",
    "- include key columns for linking multiple tables\n",
    "- the top row contains (sensible) variable names\n",
    "- in general, save data as one file per table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kmjox61xNQtW"
   },
   "source": [
    "### Dataset Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29PQdqUMNQtX"
   },
   "source": [
    "Once we have our dataset in a DataFrame (or Series, if our data is only 1-dimensional), we can start examining its size and content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04lspVeiNQtY"
   },
   "source": [
    "How many rows and columns are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkO6SxSmNQtY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 17)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "camJWA-DNQta"
   },
   "source": [
    "What are the column names in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDzIHgjXNQtb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
       "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
       "       'casual', 'registered', 'cnt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iL7Cm_4NNQtc"
   },
   "source": [
    "What are the data types of these columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtKQtrdSNQtd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant         int64\n",
       "dteday         object\n",
       "season          int64\n",
       "yr              int64\n",
       "mnth            int64\n",
       "hr              int64\n",
       "holiday         int64\n",
       "weekday         int64\n",
       "workingday      int64\n",
       "weathersit      int64\n",
       "temp          float64\n",
       "atemp         float64\n",
       "hum           float64\n",
       "windspeed     float64\n",
       "casual          int64\n",
       "registered      int64\n",
       "cnt             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqHDi7_GNQtf"
   },
   "source": [
    "What is the (row) index for this DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7WciAwrNQtf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=17379, step=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIJcLnsKNQth"
   },
   "source": [
    "https://www.dataquest.io/blog/python-json-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtxBEejpNQti"
   },
   "source": [
    "## Slicing and Dicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tzns_pFsNQtj"
   },
   "source": [
    "It is often preferable to refer to DataFrame columns by name, but there is more than one way to do this. \n",
    "Do `bikes['season']` and `bikes[['season']]` give the same object? Demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSlC2oZXNQtj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "type(bikes['season']) #gives values as series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bikes[['season']]) # it is giving the values asa complete table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsCATb2iNQtl"
   },
   "source": [
    "How would we use object notation to show the first 4 rows of `atemp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5D_UU5KNQtm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.2879\n",
       "1    0.2727\n",
       "2    0.2727\n",
       "3    0.2879\n",
       "Name: atemp, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.atemp[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sWKI9FNDNQto"
   },
   "source": [
    "Algorithms that loop over multiple columns often access DataFrame columns by index. However, none of the following work (try them out by uncommenting / removing the \"#E: \" ): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgWFEEmWNQto"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([0, 0], dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-7a2e64b3145e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#bikes[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#bikes[0,0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbikes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2934\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1244\u001b[0m                 raise KeyError(\n\u001b[0;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1246\u001b[1;33m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([0, 0], dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#bikes[[0]]\n",
    "#bikes[0]\n",
    "#bikes[0,0]\n",
    "#bikes[[0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeUJ7D5qNQtq"
   },
   "source": [
    "What is the correct way to access the 1st row of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4Kidzz0NQtq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant                1\n",
       "dteday        2011-01-01\n",
       "season                 1\n",
       "yr                     0\n",
       "mnth                   1\n",
       "hr                     0\n",
       "holiday                0\n",
       "weekday                6\n",
       "workingday             0\n",
       "weathersit             1\n",
       "temp                0.24\n",
       "atemp             0.2879\n",
       "hum                 0.81\n",
       "windspeed              0\n",
       "casual                 3\n",
       "registered            13\n",
       "cnt                   16\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.loc[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZa1v-2jNQts"
   },
   "source": [
    "What is the correct way to access the 2nd column of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4GmE0EsNQtt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2011-01-01\n",
       "1        2011-01-01\n",
       "2        2011-01-01\n",
       "3        2011-01-01\n",
       "4        2011-01-01\n",
       "5        2011-01-01\n",
       "6        2011-01-01\n",
       "7        2011-01-01\n",
       "8        2011-01-01\n",
       "9        2011-01-01\n",
       "10       2011-01-01\n",
       "11       2011-01-01\n",
       "12       2011-01-01\n",
       "13       2011-01-01\n",
       "14       2011-01-01\n",
       "15       2011-01-01\n",
       "16       2011-01-01\n",
       "17       2011-01-01\n",
       "18       2011-01-01\n",
       "19       2011-01-01\n",
       "20       2011-01-01\n",
       "21       2011-01-01\n",
       "22       2011-01-01\n",
       "23       2011-01-01\n",
       "24       2011-01-02\n",
       "25       2011-01-02\n",
       "26       2011-01-02\n",
       "27       2011-01-02\n",
       "28       2011-01-02\n",
       "29       2011-01-02\n",
       "            ...    \n",
       "17349    2012-12-30\n",
       "17350    2012-12-30\n",
       "17351    2012-12-30\n",
       "17352    2012-12-30\n",
       "17353    2012-12-30\n",
       "17354    2012-12-30\n",
       "17355    2012-12-31\n",
       "17356    2012-12-31\n",
       "17357    2012-12-31\n",
       "17358    2012-12-31\n",
       "17359    2012-12-31\n",
       "17360    2012-12-31\n",
       "17361    2012-12-31\n",
       "17362    2012-12-31\n",
       "17363    2012-12-31\n",
       "17364    2012-12-31\n",
       "17365    2012-12-31\n",
       "17366    2012-12-31\n",
       "17367    2012-12-31\n",
       "17368    2012-12-31\n",
       "17369    2012-12-31\n",
       "17370    2012-12-31\n",
       "17371    2012-12-31\n",
       "17372    2012-12-31\n",
       "17373    2012-12-31\n",
       "17374    2012-12-31\n",
       "17375    2012-12-31\n",
       "17376    2012-12-31\n",
       "17377    2012-12-31\n",
       "17378    2012-12-31\n",
       "Name: dteday, Length: 17379, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSvqNbVUNQtu"
   },
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRPFEN1HNQtu"
   },
   "source": [
    "What is the Pandas `isnull` function for? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xyw5qkWWNQtu"
   },
   "source": [
    "?\n",
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iby8s2VSNQtv"
   },
   "source": [
    "We can apply `isnull` to the `bikes` DataFrame to show the result for every element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRQY-1ViNQtv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  dteday  season     yr   mnth     hr  holiday  weekday  workingday  \\\n",
       "0    False   False   False  False  False  False    False    False       False   \n",
       "1    False   False   False  False  False  False    False    False       False   \n",
       "2    False   False   False  False  False  False    False    False       False   \n",
       "3    False   False   False  False  False  False    False    False       False   \n",
       "4    False   False   False  False  False  False    False    False       False   \n",
       "\n",
       "   weathersit   temp  atemp    hum  windspeed  casual  registered    cnt  \n",
       "0       False  False  False  False      False   False       False  False  \n",
       "1       False  False  False  False      False   False       False  False  \n",
       "2       False  False  False  False      False   False       False  False  \n",
       "3       False  False  False  False      False   False       False  False  \n",
       "4       False  False  False  False      False   False       False  False  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.isnull().head() # isnull is a boolean that returns true or false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3IyZaICINQtw"
   },
   "source": [
    "However, we usually start at a higher level. How many nulls are in `bikes` altogether?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbDfiSqVNQtx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER df.isnull().sum().sum() - This returns an integer of the total number of NaN values\n",
    "\n",
    "bikes.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "10jWUf4VNQty"
   },
   "source": [
    "If this result were nonzero we would next want to find out which columns contained nulls. How can this be done in one line of code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBv3l_s2NQtz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.columns[bikes.isna().any()].tolist()# a list of columns containing NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17349</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17350</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17351</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17352</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17353</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17354</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17355</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17356</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17357</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17358</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17359</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17360</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17361</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17362</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17363</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17364</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17365</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17366</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17367</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17368</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17369</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17370</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17371</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17372</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17373</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "\n",
       "[17379 rows x 0 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.loc[:, bikes.isna().any()] # to select those columns (containing at least one NaN value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0\n",
       "dteday        0\n",
       "season        0\n",
       "yr            0\n",
       "mnth          0\n",
       "hr            0\n",
       "holiday       0\n",
       "weekday       0\n",
       "workingday    0\n",
       "weathersit    0\n",
       "temp          0\n",
       "atemp         0\n",
       "hum           0\n",
       "windspeed     0\n",
       "casual        0\n",
       "registered    0\n",
       "cnt           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.isnull().sum() # correct way of finding which columns contained nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1MsvXf7NQt0"
   },
   "source": [
    "What is the Numpy object `nan` used for? (Write a descriptive answer.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nan means \"not a number\", a float value that you get if you perform a calculation whose result can't be expressed as a number. Any calculations you perform with NaN will also result in NaN . inf means infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaeGVh6ZNQt0"
   },
   "source": [
    "?\n",
    "ANSWER: Marking a data point as invalid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9bFlPsrNQt1"
   },
   "source": [
    "Write (and verify) a function that performs scalar division with built-in handling of the edge case (i.e. return a value instead of just trapping the error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Cq2VAb8NQt1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "def divide(dividend, divisor):\n",
    "    if divisor == 0:\n",
    "        quotient = np.nan\n",
    "    else:\n",
    "        quotient = dividend / divisor\n",
    "    return (quotient)\n",
    "\n",
    "print(divide(1, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7Up8D6lNQt2"
   },
   "source": [
    "Apply the Pandas `isna` function to the following data objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_YvVav3NQt3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3 nan\n"
     ]
    }
   ],
   "source": [
    "x = 2.3\n",
    "y = np.nan\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAcf1FU1NQt4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(pd.isna(x), pd.isna(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJUM31pANQt5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. nan  3.]\n",
      " [ 4.  5. nan]]\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LBgqnubNQt6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhFaZbzQNQt7"
   },
   "source": [
    "How is the pandas I/O parameter `na_values` used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mw-PvrTeNQt8"
   },
   "source": [
    "? ANSWER: Pandas isna() vs isnull().These two DataFrame methods do exactly the same thing! Even their docs are identical. You can even confirm this in pandas' code.\n",
    "\n",
    "But why have two methods with different names do the same thing?\n",
    "This is because pandas' DataFrames are based on R's DataFrames. In R na and null are two separate things. Read this post for more information.\n",
    "\n",
    "However, in python, pandas is built on top of numpy, which has neither na nor null values. Instead numpy has NaN values (which stands for \"Not a Number\"). Consequently, pandas also uses NaN values.\n",
    "\n",
    "In short\n",
    "To detect NaN values numpy uses np.isnan().\n",
    "\n",
    "To detect NaN values pandas uses either .isna() or .isnull().\n",
    "The NaN values are inherited from the fact that pandas is built on top of numpy, while the two functions' names originate from R's DataFrames, whose structure and functionality pandas tried to mimic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOW3ICgwNQt8"
   },
   "source": [
    "## Data Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZhJ9-XrNQt8"
   },
   "source": [
    "### Counts\n",
    "\n",
    "When there are categorical variables in a dataset we will want to know how many possible values there are in each column. (Nb. If the dataset is a sample of a larger one, our sample may not capture all possible values of every categorical.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RitKNRPCNQt8"
   },
   "source": [
    "How many (different) seasons are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqmE4OMsNQt9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       17379\n",
       "dteday        17379\n",
       "season        17379\n",
       "yr            17379\n",
       "mnth          17379\n",
       "hr            17379\n",
       "holiday       17379\n",
       "weekday       17379\n",
       "workingday    17379\n",
       "weathersit    17379\n",
       "temp          17379\n",
       "atemp         17379\n",
       "hum           17379\n",
       "windspeed     17379\n",
       "casual        17379\n",
       "registered    17379\n",
       "cnt           17379\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4496\n",
       "2    4409\n",
       "1    4242\n",
       "4    4232\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.season.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peDZrNJjNQt-"
   },
   "source": [
    "### Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KIKyD5LHNQt-"
   },
   "source": [
    "Print the range of the `instant`, `dteday`, and `windspeed` columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVAOjyocNQt-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant: 1 to 17379\n",
      "dteday: 1/01/2011 to 9/12/2012\n",
      "windspeed: 0.0 to 0.8507\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print('instant:', bikes['instant'].min(), 'to', bikes['instant'].max())\n",
    "print('dteday:', bikes['dteday'].min(), 'to', bikes['dteday'].max())\n",
    "print('windspeed:', bikes['windspeed'].min(), 'to', bikes['windspeed'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5oDTJHoNQt_"
   },
   "source": [
    "Compute and print the overall minimum and maximum of the numeric data columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiIKiPT4NQuA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant               1\n",
      "dteday        1/01/2011\n",
      "season                1\n",
      "yr                    0\n",
      "mnth                  1\n",
      "hr                    0\n",
      "holiday               0\n",
      "weekday               0\n",
      "workingday            0\n",
      "weathersit            1\n",
      "temp               0.02\n",
      "atemp                 0\n",
      "hum                   0\n",
      "windspeed             0\n",
      "casual                0\n",
      "registered            0\n",
      "cnt                   1\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "bikes_min, bikes_max = bikes.min(axis=0), bikes.max(axis=0) # use axis=0 to fetch the values from the column\n",
    "print(bikes_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyKKjxJoNQuB"
   },
   "source": [
    "### Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hxPA3sXNQuB"
   },
   "source": [
    "Pandas makes computing quantiles easy. This is how to get the median of a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1GLqWOoNQuB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4848"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['atemp'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBWCtrCrNQuD"
   },
   "source": [
    "Of course, the `quantiles` method can take a tuple as its argument. Compute the 10th, 25th, 50th, 75th, and 90th percentiles in one line of code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iu8bzEktNQuD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10    0.2424\n",
       "0.25    0.3333\n",
       "0.50    0.4848\n",
       "0.75    0.6212\n",
       "0.90    0.6970\n",
       "Name: atemp, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['atemp'].quantile([0.1, 0.25, 0.5, 0.75, 0.9]) # as it is a list it has to be in [] bracket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJnCB_bqNQuF"
   },
   "source": [
    "### Cuts\n",
    "\n",
    "Sometimes we want to split the sample not by the quantiles of the distribution but by the range of the data. Let's take a closer look at `atemp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vn_cvvY-NQuF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bikes['atemp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ae7zUQp-NQuH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>7194</td>\n",
       "      <td>1/11/2011</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.2537</td>\n",
       "      <td>17</td>\n",
       "      <td>402</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12100</th>\n",
       "      <td>12101</td>\n",
       "      <td>24/05/2012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>9896</td>\n",
       "      <td>22/02/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>9</td>\n",
       "      <td>567</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>6058</td>\n",
       "      <td>14/09/2011</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.6061</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12643</th>\n",
       "      <td>12644</td>\n",
       "      <td>16/06/2012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>25</td>\n",
       "      <td>112</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
       "7193      7194   1/11/2011       4   0    11   8        0        2   \n",
       "12100    12101  24/05/2012       2   1     5   9        0        4   \n",
       "9895      9896  22/02/2012       1   1     2   8        0        3   \n",
       "6057      6058  14/09/2011       3   0     9  23        0        3   \n",
       "12643    12644  16/06/2012       2   1     6   0        0        6   \n",
       "\n",
       "       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n",
       "7193            1           1  0.36  0.3333  0.71     0.2537      17   \n",
       "12100           1           1  0.62  0.5909  0.73     0.1642      34   \n",
       "9895            1           1  0.30  0.3182  0.75     0.0896       9   \n",
       "6057            1           2  0.64  0.6061  0.69     0.1045      10   \n",
       "12643           0           1  0.58  0.5455  0.56     0.1343      25   \n",
       "\n",
       "       registered  cnt  \n",
       "7193          402  419  \n",
       "12100         267  301  \n",
       "9895          567  576  \n",
       "6057           62   72  \n",
       "12643         112  137  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thwFHrthNQuJ"
   },
   "source": [
    "Suppose we decide to sort these values into 4 bins of equal width, but we want to apply the resulting groups to the entire DataFrame. Basically, we need to add a row label that indcates which bin each sample belongs in. Let's call this label \"atemp_level\", and use the `cut` method to populate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7mXBeXMNQuJ"
   },
   "outputs": [],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 4)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vf3Q5vbQNQuL"
   },
   "source": [
    "What is `atemp_level`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhlx1W-VNQuL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print (type(atemp_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuDXdgfxNQuN"
   },
   "source": [
    "Here is a random sample of `atemp_level`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Qure0UbNQuN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3181     (0.5, 0.75]\n",
       "10622    (0.5, 0.75]\n",
       "7091     (0.25, 0.5]\n",
       "12419    (0.5, 0.75]\n",
       "10886    (0.5, 0.75]\n",
       "Name: atemp, dtype: category\n",
       "Categories (4, interval[float64]): [(-0.001, 0.25] < (0.25, 0.5] < (0.5, 0.75] < (0.75, 1.0]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atemp_level.sample(5)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q59qWmqfNQuO"
   },
   "source": [
    "So, by default, `cut` produces labels that indicate the bin boundaries for each element in the series it was applied to. Usually, we will specify labels that are appropriate to the discretisation we are applying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYsD8ZwDNQuP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13537    warm\n",
       "8794     mild\n",
       "12587    warm\n",
       "2642     mild\n",
       "15950    mild\n",
       "Name: atemp, dtype: category\n",
       "Categories (4, object): [cool < mild < warm < hot]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 4, labels = [\"cool\", \"mild\", \"warm\", \"hot\"])\n",
    "atemp_level.sample(5)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(atemp_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes['atemp_level'] = atemp_level # create a anew column as atemp_level, check it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>atemp_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/01/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/01/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/01/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/01/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/01/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mild</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant     dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  1/01/2011       1   0     1   0        0        6           0   \n",
       "1        2  1/01/2011       1   0     1   1        0        6           0   \n",
       "2        3  1/01/2011       1   0     1   2        0        6           0   \n",
       "3        4  1/01/2011       1   0     1   3        0        6           0   \n",
       "4        5  1/01/2011       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \\\n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16   \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40   \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32   \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13   \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1   \n",
       "\n",
       "  atemp_level  \n",
       "0        mild  \n",
       "1        mild  \n",
       "2        mild  \n",
       "3        mild  \n",
       "4        mild  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WD-3g9qLNQuQ"
   },
   "source": [
    "Incorporate the new `atemp_level` column into the `bikes` DataFrame and use it to count the number of \"mild\" `atemp` entries in `season` 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5fRRbXwNQuR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1829"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes[(bikes.atemp_level == 'mild') & (bikes.season == 2)].season.count() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ZN-0yDQNQuR"
   },
   "source": [
    "*Nb. The `atemp_level` variable we created is what the R language calls a \"factor\". Pandas has introduced a new data type called \"category\" that is similar to R's factors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vxMDzgRWNQuS"
   },
   "source": [
    "# Synthetic Data\n",
    "\n",
    "Sometimes we may want to generate test data, or we may need to initalise a series, matrix, or data frame for input to an algorithm. Numpy has several methods we can use for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_W10uoBlNQuS"
   },
   "source": [
    "Execute the following, then check the shape and content of each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFR29OriNQuS"
   },
   "outputs": [],
   "source": [
    "# Creating arrays with initial values\n",
    "a = np.zeros((3))\n",
    "b = np.ones((1,3))\n",
    "c = np.random.randint(1,10,(2,3,4))   # randint(low, high, size)\n",
    "d = np.arange(4)\n",
    "e = np.array( [[1,2,3,4], [5,6,7,8]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGrvvNNANQuT"
   },
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load rock.csv and clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_csv = 'C:\\\\Users\\\\praty\\\\Documents\\\\DSIA\\DSIA-SYD-FT-Projects-201907\\\\Sarita\\\\Module 3\\\\DATA3\\\\rock.csv'\n",
    "rock = pd.read_csv(rock_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Column Names\n",
    "\n",
    "Check column names and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Song Clean', 'ARTIST CLEAN', 'Release Year', 'COMBINED', 'First?',\n",
       "       'Year?', 'PlayCount', 'F*G'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns names are not uniform.\n",
    "\n",
    "Uppercase, Lowercase > Lowercase\n",
    "Space > _\n",
    "?, * > Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_name(column_names):\n",
    "    clean_column_names = []\n",
    "    for c in column_names:\n",
    "        c = c.lower().replace(' ', '_')\n",
    "        c = c.lower().replace('*', '')\n",
    "        c = c.lower().replace('?', '')\n",
    "        clean_column_names.append(c)\n",
    "        \n",
    "    return clean_column_names  #here we are trying to clean the columns as there are uppercase, \n",
    "#lower case and so many charatceristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock.columns = clean_column_name(rock.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['song_clean', 'artist_clean', 'release_year', 'combined', 'first',\n",
       "       'year', 'playcount', 'fg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace Null Values With 0\n",
    "\n",
    "Check 'release' column whether this column have any null value or not. Replace null value with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean        0\n",
       "artist_clean      0\n",
       "release_year    577\n",
       "combined          0\n",
       "first             0\n",
       "year              0\n",
       "playcount         0\n",
       "fg                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask to find all rows with null values\n",
    "null_mask = rock['release_year'].isnull()\n",
    "rock.loc[null_mask, 'release_year'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean      0\n",
       "artist_clean    0\n",
       "release_year    0\n",
       "combined        0\n",
       "first           0\n",
       "year            0\n",
       "playcount       0\n",
       "fg              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check is there any nul values in any column\n",
    "rock.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Datatypes of Dataset\n",
    "\n",
    "Check datatypes of the dataset. Is there any column which should be int instead of object? Fix the column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans\n",
    "We can pass any Python, Numpy or Pandas datatype to change all columns of a dataframe to that type, or we can pass a dictionary having column names as keys and datatype as values to change type of selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_clean      object\n",
      "artist_clean    object\n",
      "release_year    object\n",
      "combined        object\n",
      "first            int64\n",
      "year             int64\n",
      "playcount        int64\n",
      "fg               int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(rock.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2230 entries, 0 to 2229\n",
      "Data columns (total 8 columns):\n",
      "song_clean      2230 non-null object\n",
      "artist_clean    2230 non-null object\n",
      "release_year    1653 non-null object\n",
      "combined        2230 non-null object\n",
      "first           2230 non-null int64\n",
      "year            2230 non-null int64\n",
      "playcount       2230 non-null int64\n",
      "fg              2230 non-null int64\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 139.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#dteday is object but should be integer\n",
    "rock.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                577\n",
       "1973             104\n",
       "1977              83\n",
       "1975              83\n",
       "1970              81\n",
       "1971              75\n",
       "1969              72\n",
       "1980              70\n",
       "1978              64\n",
       "1979              63\n",
       "1981              61\n",
       "1967              61\n",
       "1983              60\n",
       "1976              56\n",
       "1982              54\n",
       "1984              51\n",
       "1972              50\n",
       "1974              48\n",
       "1968              46\n",
       "1985              39\n",
       "1987              39\n",
       "1986              37\n",
       "1991              34\n",
       "1989              32\n",
       "1966              30\n",
       "1988              29\n",
       "1965              28\n",
       "1994              25\n",
       "1990              22\n",
       "1993              19\n",
       "1964              14\n",
       "1992              14\n",
       "1999              13\n",
       "1995              10\n",
       "1997               9\n",
       "1996               9\n",
       "1963               9\n",
       "1998               6\n",
       "2002               6\n",
       "2005               5\n",
       "2012               5\n",
       "2004               5\n",
       "2001               4\n",
       "2011               3\n",
       "1962               3\n",
       "2007               3\n",
       "2000               3\n",
       "2003               3\n",
       "2008               3\n",
       "2013               2\n",
       "2014               2\n",
       "2006               1\n",
       "SONGFACTS.COM      1\n",
       "1961               1\n",
       "1958               1\n",
       "1071               1\n",
       "1955               1\n",
       "Name: release_year, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chekc values of release_year\n",
    "\n",
    "rock['release_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praty\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "# here we see that songfacts .com is not a release year and want to replace it\n",
    "# Create a mask to find all rows with SONGFACTS.COM\n",
    "song_facts_mask = rock['release_year'] == 'SONGFACTS.COM'\n",
    "rock.loc[song_facts_mask, 'release_year'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "5       False\n",
       "6       False\n",
       "7       False\n",
       "8       False\n",
       "9       False\n",
       "10      False\n",
       "11      False\n",
       "12      False\n",
       "13      False\n",
       "14      False\n",
       "15      False\n",
       "16      False\n",
       "17      False\n",
       "18      False\n",
       "19      False\n",
       "20      False\n",
       "21      False\n",
       "22      False\n",
       "23      False\n",
       "24      False\n",
       "25      False\n",
       "26      False\n",
       "27      False\n",
       "28      False\n",
       "29      False\n",
       "        ...  \n",
       "2200    False\n",
       "2201    False\n",
       "2202    False\n",
       "2203    False\n",
       "2204    False\n",
       "2205    False\n",
       "2206    False\n",
       "2207    False\n",
       "2208    False\n",
       "2209    False\n",
       "2210    False\n",
       "2211    False\n",
       "2212    False\n",
       "2213    False\n",
       "2214    False\n",
       "2215    False\n",
       "2216    False\n",
       "2217    False\n",
       "2218    False\n",
       "2219    False\n",
       "2220    False\n",
       "2221    False\n",
       "2222    False\n",
       "2223    False\n",
       "2224    False\n",
       "2225    False\n",
       "2226    False\n",
       "2227    False\n",
       "2228    False\n",
       "2229    False\n",
       "Name: release_year, Length: 2230, dtype: bool"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_facts_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert release year to numeric\n",
    "rock['release_year'] = pd.to_numeric(rock['release_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       577\n",
       "1973.0    104\n",
       "1975.0     83\n",
       "1977.0     83\n",
       "1970.0     81\n",
       "1971.0     75\n",
       "1969.0     72\n",
       "1980.0     70\n",
       "1978.0     64\n",
       "1979.0     63\n",
       "1981.0     61\n",
       "1967.0     61\n",
       "1983.0     60\n",
       "1976.0     56\n",
       "1982.0     54\n",
       "1984.0     51\n",
       "1972.0     50\n",
       "1974.0     48\n",
       "1968.0     46\n",
       "1985.0     39\n",
       "1987.0     39\n",
       "1986.0     37\n",
       "1991.0     34\n",
       "1989.0     32\n",
       "1966.0     30\n",
       "1988.0     29\n",
       "1965.0     28\n",
       "1994.0     25\n",
       "1990.0     22\n",
       "1993.0     19\n",
       "1992.0     14\n",
       "1964.0     14\n",
       "1999.0     13\n",
       "1995.0     10\n",
       "1963.0      9\n",
       "1996.0      9\n",
       "1997.0      9\n",
       "1998.0      6\n",
       "2002.0      6\n",
       "2004.0      5\n",
       "2005.0      5\n",
       "2012.0      5\n",
       "2001.0      4\n",
       "2000.0      3\n",
       "2007.0      3\n",
       "2011.0      3\n",
       "1962.0      3\n",
       "2003.0      3\n",
       "2008.0      3\n",
       "2013.0      2\n",
       "2014.0      2\n",
       "2006.0      1\n",
       "1955.0      1\n",
       "1958.0      1\n",
       "NaN         1\n",
       "1961.0      1\n",
       "1071.0      1\n",
       "Name: release_year, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock['release_year'].value_counts(dropna=False) # to check nan and it also shows the values with decimal points\n",
    "#so converted to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean       object\n",
       "artist_clean     object\n",
       "release_year    float64\n",
       "combined         object\n",
       "first             int64\n",
       "year              int64\n",
       "playcount         int64\n",
       "fg                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Min, Max of Each Column\n",
    "\n",
    "Is there any illogical value in any column? How can we fix that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_min_max(df):\n",
    "    # Check min, max of each column\n",
    "    print(df.describe().T[['min', 'max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              min     max\n",
      "release_year  0.0  2014.0\n",
      "first         1.0     1.0\n",
      "year          0.0     1.0\n",
      "playcount     0.0   142.0\n",
      "fg            0.0   142.0\n"
     ]
    }
   ],
   "source": [
    "check_min_max(rock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum Value of release year is 0, which is wrong, so we need to mask it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_facts_mask = rock['release_year'] == 0\n",
    "rock.loc[song_facts_mask, 'release_year'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(song_facts_mask)# so we have created a series with Boolians to look for the NAN vaues, instead of creating a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 min     max\n",
      "release_year  1955.0  2014.0\n",
      "first            1.0     1.0\n",
      "year             0.0     1.0\n",
      "playcount        0.0   142.0\n",
      "fg               0.0   142.0\n"
     ]
    }
   ],
   "source": [
    "check_min_max(rock) # when you use NaN the value is not seen and that nan is not considered to be important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still minimum value is 1071. It's very unlikely there were any rock song in that year! This is not a correct value\n",
    "song_facts_mask = rock['release_year'] == 1071.0\n",
    "rock.loc[song_facts_mask, 'release_year'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 min     max\n",
      "release_year  1955.0  2014.0\n",
      "first            1.0     1.0\n",
      "year             0.0     1.0\n",
      "playcount        0.0   142.0\n",
      "fg               0.0   142.0\n"
     ]
    }
   ],
   "source": [
    "check_min_max(rock) # this is more logical, 1955"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Some Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function that will take a row of a DataFrame and print out the song, artist, and whether or not the release date is < 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean       object\n",
       "artist_clean     object\n",
       "release_year    float64\n",
       "combined         object\n",
       "first             int64\n",
       "year              int64\n",
       "playcount         int64\n",
       "fg                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_song(row):\n",
    "    print('Song: ', row['song_clean'])\n",
    "    print('Artist: ', row['artist_clean'])\n",
    "    print('Released before 1970: ', row['release_year'] < 1970)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean                     Caught Up in You\n",
       "artist_clean                        .38 Special\n",
       "release_year                               1982\n",
       "combined        Caught Up in You by .38 Special\n",
       "first                                         1\n",
       "year                                          1\n",
       "playcount                                    82\n",
       "fg                                           82\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.iloc[0] # above is the function and the below is the idea of calling the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song:  Caught Up in You\n",
      "Artist:  .38 Special\n",
      "Released before 1970:  False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check any row using index\n",
    "check_song(rock.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean                     Fantasy Girl\n",
       "artist_clean                    .38 Special\n",
       "release_year                            NaN\n",
       "combined        Fantasy Girl by .38 Special\n",
       "first                                     1\n",
       "year                                      0\n",
       "playcount                                 3\n",
       "fg                                        0\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song:  Fantasy Girl\n",
      "Artist:  .38 Special\n",
      "Released before 1970:  False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_song(rock.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_clean</th>\n",
       "      <th>artist_clean</th>\n",
       "      <th>release_year</th>\n",
       "      <th>combined</th>\n",
       "      <th>first</th>\n",
       "      <th>year</th>\n",
       "      <th>playcount</th>\n",
       "      <th>fg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caught Up in You</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>Caught Up in You by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fantasy Girl</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fantasy Girl by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hold On Loosely</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Hold On Loosely by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rockin' Into the Night</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>Rockin' Into the Night by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Art For Arts Sake</td>\n",
       "      <td>10cc</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>Art For Arts Sake by 10cc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               song_clean artist_clean  release_year  \\\n",
       "0        Caught Up in You  .38 Special        1982.0   \n",
       "1            Fantasy Girl  .38 Special           NaN   \n",
       "2         Hold On Loosely  .38 Special        1981.0   \n",
       "3  Rockin' Into the Night  .38 Special        1980.0   \n",
       "4       Art For Arts Sake         10cc        1975.0   \n",
       "\n",
       "                                combined  first  year  playcount  fg  \n",
       "0        Caught Up in You by .38 Special      1     1         82  82  \n",
       "1            Fantasy Girl by .38 Special      1     0          3   0  \n",
       "2         Hold On Loosely by .38 Special      1     1         85  85  \n",
       "3  Rockin' Into the Night by .38 Special      1     1         18  18  \n",
       "4              Art For Arts Sake by 10cc      1     1          1   1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song:  0          Caught Up in You\n",
      "1              Fantasy Girl\n",
      "2           Hold On Loosely\n",
      "3    Rockin' Into the Night\n",
      "4         Art For Arts Sake\n",
      "Name: song_clean, dtype: object\n",
      "Artist:  0    .38 Special\n",
      "1    .38 Special\n",
      "2    .38 Special\n",
      "3    .38 Special\n",
      "4           10cc\n",
      "Name: artist_clean, dtype: object\n",
      "Released before 1970:  0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: release_year, dtype: bool\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_song(rock.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song:  Caught Up in You\n",
      "Artist:  .38 Special\n",
      "Released before 1970:  False\n",
      "\n",
      "\n",
      "Song:  Fantasy Girl\n",
      "Artist:  .38 Special\n",
      "Released before 1970:  False\n",
      "\n",
      "\n",
      "Song:  Hold On Loosely\n",
      "Artist:  .38 Special\n",
      "Released before 1970:  False\n",
      "\n",
      "\n",
      "Song:  Rockin' Into the Night\n",
      "Artist:  .38 Special\n",
      "Released before 1970:  False\n",
      "\n",
      "\n",
      "Song:  Art For Arts Sake\n",
      "Artist:  10cc\n",
      "Released before 1970:  False\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first five rows\n",
    "rock.head(5).apply(check_song, axis=1)# the one above is in the form of a group and this one is in the form of a different group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function that converts cells in a DataFrame to float and otherwise replaces them with np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(column):\n",
    "    column = pd.to_numeric(column, errors='coerce')\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply these functions to your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_clean</th>\n",
       "      <th>artist_clean</th>\n",
       "      <th>release_year</th>\n",
       "      <th>combined</th>\n",
       "      <th>first</th>\n",
       "      <th>year</th>\n",
       "      <th>playcount</th>\n",
       "      <th>fg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caught Up in You</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>Caught Up in You by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fantasy Girl</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fantasy Girl by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hold On Loosely</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Hold On Loosely by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rockin' Into the Night</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>Rockin' Into the Night by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Art For Arts Sake</td>\n",
       "      <td>10cc</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>Art For Arts Sake by 10cc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               song_clean artist_clean  release_year  \\\n",
       "0        Caught Up in You  .38 Special        1982.0   \n",
       "1            Fantasy Girl  .38 Special           NaN   \n",
       "2         Hold On Loosely  .38 Special        1981.0   \n",
       "3  Rockin' Into the Night  .38 Special        1980.0   \n",
       "4       Art For Arts Sake         10cc        1975.0   \n",
       "\n",
       "                                combined  first  year  playcount  fg  \n",
       "0        Caught Up in You by .38 Special      1     1         82  82  \n",
       "1            Fantasy Girl by .38 Special      1     0          3   0  \n",
       "2         Hold On Loosely by .38 Special      1     1         85  85  \n",
       "3  Rockin' Into the Night by .38 Special      1     1         18  18  \n",
       "4              Art For Arts Sake by 10cc      1     1          1   1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_clean</th>\n",
       "      <th>artist_clean</th>\n",
       "      <th>release_year</th>\n",
       "      <th>combined</th>\n",
       "      <th>first</th>\n",
       "      <th>year</th>\n",
       "      <th>playcount</th>\n",
       "      <th>fg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2230 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_clean  artist_clean  release_year  combined  first  year  \\\n",
       "0            NaN           NaN        1982.0       NaN      1     1   \n",
       "1            NaN           NaN           NaN       NaN      1     0   \n",
       "2            NaN           NaN        1981.0       NaN      1     1   \n",
       "3            NaN           NaN        1980.0       NaN      1     1   \n",
       "4            NaN           NaN        1975.0       NaN      1     1   \n",
       "5            NaN           NaN        2000.0       NaN      1     1   \n",
       "6            NaN           NaN        2000.0       NaN      1     1   \n",
       "7            NaN           NaN        2002.0       NaN      1     1   \n",
       "8            NaN           NaN        1992.0       NaN      1     1   \n",
       "9            NaN           NaN        1985.0       NaN      1     1   \n",
       "10           NaN           NaN           NaN       NaN      1     0   \n",
       "11           NaN           NaN        1980.0       NaN      1     1   \n",
       "12           NaN           NaN        1993.0       NaN      1     1   \n",
       "13           NaN           NaN           NaN       NaN      1     0   \n",
       "14           NaN           NaN        1976.0       NaN      1     1   \n",
       "15           NaN           NaN        1981.0       NaN      1     1   \n",
       "16           NaN           NaN           NaN       NaN      1     0   \n",
       "17           NaN           NaN        1995.0       NaN      1     1   \n",
       "18           NaN           NaN        1980.0       NaN      1     1   \n",
       "19           NaN           NaN        1980.0       NaN      1     1   \n",
       "20           NaN           NaN        1979.0       NaN      1     1   \n",
       "21           NaN           NaN        1975.0       NaN      1     1   \n",
       "22           NaN           NaN        1984.0       NaN      1     1   \n",
       "23           NaN           NaN        1977.0       NaN      1     1   \n",
       "24           NaN           NaN           NaN       NaN      1     0   \n",
       "25           NaN           NaN           NaN       NaN      1     0   \n",
       "26           NaN           NaN           NaN       NaN      1     0   \n",
       "27           NaN           NaN        1979.0       NaN      1     1   \n",
       "28           NaN           NaN        1980.0       NaN      1     1   \n",
       "29           NaN           NaN           NaN       NaN      1     0   \n",
       "...          ...           ...           ...       ...    ...   ...   \n",
       "2200         NaN           NaN        1983.0       NaN      1     1   \n",
       "2201         NaN           NaN        1971.0       NaN      1     1   \n",
       "2202         NaN           NaN        1971.0       NaN      1     1   \n",
       "2203         NaN           NaN           NaN       NaN      1     0   \n",
       "2204         NaN           NaN        1971.0       NaN      1     1   \n",
       "2205         NaN           NaN           NaN       NaN      1     0   \n",
       "2206         NaN           NaN           NaN       NaN      1     0   \n",
       "2207         NaN           NaN        1968.0       NaN      1     1   \n",
       "2208         NaN           NaN           NaN       NaN      1     0   \n",
       "2209         NaN           NaN        1976.0       NaN      1     1   \n",
       "2210         NaN           NaN        1973.0       NaN      1     1   \n",
       "2211         NaN           NaN        1980.0       NaN      1     1   \n",
       "2212         NaN           NaN        1983.0       NaN      1     1   \n",
       "2213         NaN           NaN        1983.0       NaN      1     1   \n",
       "2214         NaN           NaN        1975.0       NaN      1     1   \n",
       "2215         NaN           NaN           NaN       NaN      1     0   \n",
       "2216         NaN           NaN           NaN       NaN      1     0   \n",
       "2217         NaN           NaN        1973.0       NaN      1     1   \n",
       "2218         NaN           NaN           NaN       NaN      1     0   \n",
       "2219         NaN           NaN        1973.0       NaN      1     1   \n",
       "2220         NaN           NaN        1983.0       NaN      1     1   \n",
       "2221         NaN           NaN           NaN       NaN      1     0   \n",
       "2222         NaN           NaN           NaN       NaN      1     0   \n",
       "2223         NaN           NaN        1981.0       NaN      1     1   \n",
       "2224         NaN           NaN        1983.0       NaN      1     1   \n",
       "2225         NaN           NaN           NaN       NaN      1     0   \n",
       "2226         NaN           NaN        1981.0       NaN      1     1   \n",
       "2227         NaN           NaN        1975.0       NaN      1     1   \n",
       "2228         NaN           NaN        1983.0       NaN      1     1   \n",
       "2229         NaN           NaN        1973.0       NaN      1     1   \n",
       "\n",
       "      playcount   fg  \n",
       "0            82   82  \n",
       "1             3    0  \n",
       "2            85   85  \n",
       "3            18   18  \n",
       "4             1    1  \n",
       "5            13   13  \n",
       "6             1    1  \n",
       "7             6    6  \n",
       "8             3    3  \n",
       "9             1    1  \n",
       "10            1    0  \n",
       "11           97   97  \n",
       "12            6    6  \n",
       "13            5    0  \n",
       "14           85   85  \n",
       "15           46   46  \n",
       "16           24    0  \n",
       "17            1    1  \n",
       "18           39   39  \n",
       "19           74   74  \n",
       "20           92   92  \n",
       "21           39   39  \n",
       "22            1    1  \n",
       "23            3    3  \n",
       "24            4    0  \n",
       "25            2    0  \n",
       "26           20    0  \n",
       "27            1    1  \n",
       "28           21   21  \n",
       "29           45    0  \n",
       "...         ...  ...  \n",
       "2200         81   81  \n",
       "2201         44   44  \n",
       "2202          1    1  \n",
       "2203          5    0  \n",
       "2204          1    1  \n",
       "2205          2    0  \n",
       "2206          1    0  \n",
       "2207         14   14  \n",
       "2208          1    0  \n",
       "2209          1    1  \n",
       "2210          8    8  \n",
       "2211         34   34  \n",
       "2212         86   86  \n",
       "2213         29   29  \n",
       "2214          2    2  \n",
       "2215         16    0  \n",
       "2216         10    0  \n",
       "2217          6    6  \n",
       "2218          2    0  \n",
       "2219        111  111  \n",
       "2220        121  121  \n",
       "2221          1    0  \n",
       "2222         14    0  \n",
       "2223          5    5  \n",
       "2224        120  120  \n",
       "2225          1    0  \n",
       "2226         32   32  \n",
       "2227        109  109  \n",
       "2228          1    1  \n",
       "2229          2    2  \n",
       "\n",
       "[2230 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.apply(convert_to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the new float-only DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>release_year</th>\n",
       "      <td>1651.0</td>\n",
       "      <td>1978.569352</td>\n",
       "      <td>9.309780</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>0.741256</td>\n",
       "      <td>0.438043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playcount</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>16.872646</td>\n",
       "      <td>25.302972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fg</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>15.048430</td>\n",
       "      <td>25.288366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count         mean        std     min     25%     50%     75%  \\\n",
       "release_year  1651.0  1978.569352   9.309780  1955.0  1971.0  1977.0  1984.0   \n",
       "first         2230.0     1.000000   0.000000     1.0     1.0     1.0     1.0   \n",
       "year          2230.0     0.741256   0.438043     0.0     0.0     1.0     1.0   \n",
       "playcount     2230.0    16.872646  25.302972     0.0     1.0     4.0    21.0   \n",
       "fg            2230.0    15.048430  25.288366     0.0     0.0     3.0    18.0   \n",
       "\n",
       "                 max  \n",
       "release_year  2014.0  \n",
       "first            1.0  \n",
       "year             1.0  \n",
       "playcount      142.0  \n",
       "fg             142.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe Dataframe. All columns are float.\n",
    "rock.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hj8GdoOXC-Lu"
   },
   "source": [
    "\n",
    "\n",
    "> \n",
    ">\n",
    ">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YLHUmjnDDZq"
   },
   "source": [
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Nov8gGCDExO"
   },
   "source": [
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w2asO3_lDFm8"
   },
   "source": [
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlasiTKgDGdA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> > > > > > > >   © 2019 Data Science Institute of Australia\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Q0G5PtA2NQtC",
    "pTkOz1KsNQtK",
    "jS7P3oXQNQtL",
    "kGgcXCzyNQtN",
    "CaWhHAk9NQtQ",
    "ppLnAmKVNQtQ",
    "Kmjox61xNQtW",
    "JZhJ9-XrNQt8",
    "peDZrNJjNQt-",
    "OyKKjxJoNQuB",
    "EJnCB_bqNQuF"
   ],
   "name": "DSIA Lab 3.1.1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
